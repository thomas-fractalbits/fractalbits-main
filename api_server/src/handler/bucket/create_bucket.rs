use axum::{
    extract::Request,
    http::{header, HeaderValue},
    response::{IntoResponse, Response},
};
use bucket_tables::{
    api_key_table::{ApiKey, ApiKeyTable},
    bucket_table::{Bucket, BucketTable},
    permission::BucketKeyPerm,
    table::{Table, Versioned},
};
use bytes::Buf;
use http_body_util::BodyExt;
use rpc_client_nss::{rpc::create_root_inode_response, RpcClientNss};
use rpc_client_rss::{ArcRpcClientRss, RpcErrorRss};
use serde::{Deserialize, Serialize};

use crate::handler::common::s3_error::S3Error;

#[derive(Default, Debug, Serialize, Deserialize, PartialEq, Eq)]
#[serde(rename_all = "PascalCase")]
struct CreateBucketConfiguration {
    #[serde(default)]
    location_constraint: String,
    #[serde(default)]
    location: Location,
    #[serde(default)]
    bucket: BucketConfig,
}

#[derive(Default, Debug, Serialize, Deserialize, PartialEq, Eq)]
#[serde(rename_all = "PascalCase")]
struct Location {
    name: String,
    #[serde(rename = "Type")]
    location_type: String,
}

#[derive(Default, Debug, Serialize, Deserialize, PartialEq, Eq)]
#[serde(rename_all = "PascalCase")]
struct BucketConfig {
    data_redundancy: String,
    #[serde(rename = "Type")]
    bucket_type: String,
}

pub async fn create_bucket(
    api_key: Option<Versioned<ApiKey>>,
    bucket_name: String,
    request: Request,
    rpc_client_nss: &RpcClientNss,
    rpc_client_rss: ArcRpcClientRss,
    region: &str,
) -> Result<Response, S3Error> {
    let api_key_id = match api_key {
        None => return Err(S3Error::InvalidAccessKeyId),
        Some(api_key) => {
            if api_key.data.authorized_buckets.contains_key(&bucket_name) {
                return Err(S3Error::BucketAlreadyExists);
            }
            if !api_key.data.allow_create_bucket {
                return Err(S3Error::AccessDenied);
            }
            api_key.data.key_id.clone()
        }
    };

    let body = request.into_body().collect().await.unwrap().to_bytes();
    if !body.is_empty() {
        let create_bucket_conf: CreateBucketConfiguration =
            quick_xml::de::from_reader(body.reader())?;
        let location_constraint = create_bucket_conf.location_constraint;
        if !location_constraint.is_empty() && location_constraint != region {
            return Err(S3Error::InvalidLocationConstraint);
        }
    }

    let resp = rpc_client_nss
        .create_root_inode(bucket_name.clone())
        .await?;
    let root_blob_name = match resp.result.unwrap() {
        create_root_inode_response::Result::Ok(res) => res,
        create_root_inode_response::Result::Err(e) => {
            tracing::error!(e);
            return Err(S3Error::InternalError);
        }
    };

    let mut bucket_table: Table<ArcRpcClientRss, BucketTable> = Table::new(rpc_client_rss.clone());
    if bucket_table.get(bucket_name.clone()).await.is_ok() {
        return Err(S3Error::BucketAlreadyExists);
    }

    let mut bucket = Versioned::new(0, Bucket::new(bucket_name.clone(), root_blob_name));
    let bucket_key_perm = BucketKeyPerm::ALL_PERMISSIONS;
    bucket
        .data
        .authorized_keys
        .insert(api_key_id.clone(), bucket_key_perm);
    tracing::debug!("putting bucket_table with {bucket_name}");
    bucket_table.put(&bucket).await?;
    tracing::debug!("putting bucket_table with {bucket_name} done");

    let retry_times = 10;
    for i in 0..retry_times {
        let mut api_key_table: Table<ArcRpcClientRss, ApiKeyTable> =
            Table::new(rpc_client_rss.clone());
        let mut api_key = api_key_table.get(api_key_id.clone()).await?;
        api_key
            .data
            .authorized_buckets
            .insert(bucket_name.clone(), bucket_key_perm);
        tracing::debug!(
            "Inserting {} into api_key {} (retry={})",
            bucket_name.clone(),
            api_key_id.clone(),
            i,
        );
        match api_key_table.put(&api_key).await {
            Err(RpcErrorRss::Retry) => continue,
            Ok(_) => {
                return Ok([(
                    header::LOCATION,
                    HeaderValue::from_str(&format!("/{bucket_name}")).unwrap(),
                )]
                .into_response())
            }
            Err(e) => return Err(e.into()),
        }
    }

    tracing::error!("Inserting {bucket_name} into api_key {api_key_id} failed after retrying {retry_times} times");
    // TODO: wrap multiple kv updates into etcd txn and send them through rpc call, since it may
    // leave etcd datebase into an inconsistent state
    Err(S3Error::InternalError)
}
