use crate::RpcError;
use bytes::BytesMut;
use metrics::{counter, gauge};
use rpc_codec_common::{BumpBuf, MessageFrame, MessageHeaderTrait};
use socket2::{Socket, TcpKeepalive};
use std::collections::HashMap;
use std::io;
use std::io::IoSlice;
use std::marker::PhantomData;
use std::net::SocketAddr;
use std::os::fd::RawFd;
use std::os::unix::io::AsRawFd;
use std::sync::Arc;
use std::sync::atomic::{AtomicBool, Ordering};
use std::time::Duration;
use strum::AsRefStr;
use tokio::sync::oneshot;
use tokio::task::AbortHandle;
use tokio_retry::{
    Retry,
    strategy::{FixedInterval, jitter},
};
use tracing::{debug, warn};

use bumpalo::Bump;
use std::cell::RefCell;
use std::ops::Deref;
use std::rc::Rc;

thread_local! {
    static REQUEST_BUMPS: RefCell<HashMap<u64, Rc<dyn Deref<Target = Bump>>>> =
        RefCell::new(HashMap::with_capacity(8192));
}

pub fn register_request_bump<T: Deref<Target = Bump> + 'static>(trace_id: u64, bump: Rc<T>) {
    REQUEST_BUMPS.with(|map| {
        map.borrow_mut().insert(trace_id, bump);
    });
}

pub fn unregister_request_bump(trace_id: u64) {
    REQUEST_BUMPS.with(|map| map.borrow_mut().remove(&trace_id));
}

pub fn get_request_bump(trace_id: u64) -> Option<Rc<dyn Deref<Target = Bump>>> {
    REQUEST_BUMPS.with(|map| map.borrow().get(&trace_id).cloned())
}

type RequestMap<Header> =
    Arc<parking_lot::Mutex<HashMap<u32, oneshot::Sender<MessageFrame<Header>>>>>;

pub trait RpcCodec<Header: MessageHeaderTrait>: Default + Clone + Send + Sync + 'static {
    const RPC_TYPE: &'static str;
}

pub struct RpcClient<Codec: RpcCodec<Header>, Header: MessageHeaderTrait> {
    requests: RequestMap<Header>,
    writer: Arc<tokio::sync::Mutex<tokio::net::tcp::OwnedWriteHalf>>,
    recv_task_handle: AbortHandle,
    socket_fd: RawFd,
    is_closed: Arc<AtomicBool>,
    _phantom: PhantomData<Codec>,
}

#[derive(AsRefStr)]
#[strum(serialize_all = "snake_case")]
enum DrainFrom {
    ReceiveTask,
    RpcClient,
}

impl<Codec: RpcCodec<Header>, Header: MessageHeaderTrait> Drop for RpcClient<Codec, Header> {
    fn drop(&mut self) {
        debug!(rpc_type = Codec::RPC_TYPE, socket_fd = %self.socket_fd, "RpcClient dropped, aborting tasks");
        self.recv_task_handle.abort();
        Self::drain_pending_requests(self.socket_fd, &self.requests, DrainFrom::RpcClient);
    }
}

impl<Codec, Header> RpcClient<Codec, Header>
where
    Codec: RpcCodec<Header>,
    Header: MessageHeaderTrait + Clone + Send + Sync + 'static,
{
    async fn resolve_address(addr_str: &str) -> Result<SocketAddr, io::Error> {
        // Try to parse as SocketAddr first (for backward compatibility with IP addresses)
        if let Ok(socket_addr) = addr_str.parse::<SocketAddr>() {
            return Ok(socket_addr);
        }

        // Use tokio's native async DNS resolution
        let mut addrs = tokio::net::lookup_host(addr_str).await?;
        addrs.next().ok_or_else(|| {
            io::Error::new(
                io::ErrorKind::NotFound,
                format!("No addresses found for '{addr_str}'"),
            )
        })
    }

    async fn new_internal_tokio(stream: tokio::net::TcpStream) -> Result<Self, RpcError> {
        let rpc_type = Codec::RPC_TYPE;
        let socket_fd = stream.as_raw_fd();
        let (reader, writer) = stream.into_split();
        let requests: RequestMap<Header> = Arc::new(parking_lot::Mutex::new(HashMap::new()));
        let is_closed = Arc::new(AtomicBool::new(false));
        let writer = Arc::new(tokio::sync::Mutex::new(writer));

        // Receive task
        let recv_handle = {
            let receiver_requests = requests.clone();
            let is_closed = is_closed.clone();
            tokio::task::spawn_local(async move {
                if let Err(e) =
                    Self::receive_task_tokio(reader, &receiver_requests, socket_fd, rpc_type).await
                {
                    warn!(%rpc_type, %socket_fd, %e, "receive task failed");
                }
                is_closed.store(true, Ordering::SeqCst);
                Self::drain_pending_requests(socket_fd, &receiver_requests, DrainFrom::ReceiveTask);
            })
            .abort_handle()
        };

        debug!(%rpc_type, %socket_fd, "Creating RPC client");

        Ok(RpcClient {
            requests,
            writer,
            recv_task_handle: recv_handle,
            socket_fd,
            is_closed,
            _phantom: PhantomData,
        })
    }

    async fn receive_task_tokio(
        mut receiver: tokio::net::tcp::OwnedReadHalf,
        requests: &RequestMap<Header>,
        socket_fd: RawFd,
        rpc_type: &'static str,
    ) -> Result<(), RpcError> {
        use tokio::io::AsyncReadExt;

        let header_size = Header::SIZE;

        loop {
            // Read fixed-size header into stack buffer
            let mut header_buf = [0u8; 256];
            let header = match receiver.read_exact(&mut header_buf[..header_size]).await {
                Ok(_) => Header::decode(&header_buf[..header_size]),
                Err(e) if e.kind() == std::io::ErrorKind::UnexpectedEof => {
                    warn!(%rpc_type, %socket_fd, "connection closed, receive message task quit");
                    return Ok(());
                }
                Err(e) => return Err(RpcError::IoError(e)),
            };

            // Read body using bump allocator if available
            let body_size = header.get_body_size();
            let body = if body_size > 0 {
                let trace_id = header.get_trace_id();
                if trace_id != 0
                    && let Some(bump_rc) = get_request_bump(trace_id)
                {
                    // Use bump allocator for body - read directly into bump buffer
                    let bump_ref: &Bump = &bump_rc;
                    let mut bump_buf = BumpBuf::with_capacity_in(body_size, bump_ref);

                    // Read directly into BumpBuf using read_buf (zero-copy)
                    while bump_buf.len() < body_size {
                        let n = receiver.read_buf(&mut bump_buf).await?;
                        if n == 0 {
                            return Err(RpcError::IoError(std::io::Error::new(
                                std::io::ErrorKind::UnexpectedEof,
                                "connection closed while reading body",
                            )));
                        }
                    }

                    bump_buf.freeze()
                } else {
                    // No bump allocator, use ByteMut
                    let mut body_buf = bytes::BytesMut::with_capacity(body_size);
                    body_buf.resize(body_size, 0);
                    receiver.read_exact(&mut body_buf).await?;
                    body_buf.freeze()
                }
            } else {
                bytes::Bytes::new()
            };

            let frame = MessageFrame::new(header, body);
            Self::handle_incoming_frame(frame, requests, socket_fd, rpc_type);
        }
    }

    fn handle_incoming_frame(
        frame: MessageFrame<Header>,
        requests: &RequestMap<Header>,
        socket_fd: RawFd,
        rpc_type: &'static str,
    ) {
        let request_id = frame.header.get_id();
        debug!(%rpc_type, %socket_fd, %request_id, "receiving response:");
        counter!("rpc_response_received", "type" => rpc_type, "name" => "all").increment(1);
        let tx: oneshot::Sender<MessageFrame<Header>> = match requests.lock().remove(&request_id) {
            Some(tx) => tx,
            None => {
                warn!(%rpc_type, %socket_fd, %request_id,
                    "received rpc message with id not in the resp_map");
                return;
            }
        };
        gauge!("rpc_request_pending_in_resp_map", "type" => rpc_type).decrement(1.0);
        if tx.send(frame).is_err() {
            warn!(%rpc_type, %socket_fd, %request_id, "oneshot response send failed");
        }
    }

    fn drain_pending_requests(
        socket_fd: RawFd,
        requests: &RequestMap<Header>,
        drain_from: DrainFrom,
    ) {
        let mut requests = requests.lock();
        let pending_count = requests.len();
        if pending_count > 0 {
            warn!(
                rpc_type = %Codec::RPC_TYPE,
                %socket_fd,
                "draining {pending_count} pending requests from {} on connection close",
                drain_from.as_ref()
            );
            gauge!("rpc_request_pending_in_resp_map", "type" => Codec::RPC_TYPE)
                .decrement(pending_count as f64);
            requests.clear(); // This drops the senders, notifying receivers of an error.
        }
    }

    async fn send_request_internal<B: AsRef<[u8]>>(
        &self,
        request_id: u32,
        retry_count: u32,
        mut frame: MessageFrame<Header, B>,
        timeout: Option<Duration>,
    ) -> Result<MessageFrame<Header>, RpcError> {
        use tokio::io::AsyncWriteExt;

        if self.is_closed.load(Ordering::SeqCst) {
            return Err(RpcError::InternalRequestError(
                "Connection is closed".into(),
            ));
        }

        let rpc_type = Codec::RPC_TYPE;
        let trace_id = frame.header.get_trace_id();
        frame.header.set_id(request_id);
        frame.header.set_retry_count(retry_count);

        let (tx, rx) = oneshot::channel();
        self.requests.lock().insert(request_id, tx);
        gauge!("rpc_request_pending_in_resp_map", "type" => rpc_type).increment(1.0);

        debug!(%rpc_type, socket_fd=%self.socket_fd, %request_id, %trace_id, "sending request");

        let mut header_bytes = BytesMut::with_capacity(Header::SIZE);
        frame.header.encode(&mut header_bytes);
        let body_buf = frame.body.as_ref();
        let iov = if body_buf.is_empty() {
            vec![IoSlice::new(&header_bytes[..])]
        } else {
            vec![IoSlice::new(&header_bytes[..]), IoSlice::new(body_buf)]
        };

        let mut writer = self.writer.lock().await;
        writer
            .write_vectored(&iov)
            .await
            .map_err(RpcError::IoError)?;

        counter!("rpc_request_sent", "type" => rpc_type, "name" => "all").increment(1);

        drop(writer);

        let result = match timeout {
            None => rx.await,
            Some(rpc_timeout) => match tokio::time::timeout(rpc_timeout, rx).await {
                Ok(result) => result,
                Err(_) => {
                    warn!(%rpc_type, socket_fd=%self.socket_fd, %request_id, "rpc request timeout");
                    return Err(RpcError::InternalResponseError("timeout".into()));
                }
            },
        };
        result.map_err(|e| RpcError::InternalResponseError(e.to_string()))
    }

    pub async fn send_request<B: AsRef<[u8]>>(
        &self,
        request_id: u32,
        mut frame: MessageFrame<Header, B>,
        timeout: Option<std::time::Duration>,
        trace_id: Option<u64>,
    ) -> Result<MessageFrame<Header>, RpcError> {
        if let Some(trace_id) = trace_id {
            frame.header.set_trace_id(trace_id);
        }
        self.send_request_internal(request_id, 0, frame, timeout)
            .await
    }

    pub fn is_closed(&self) -> bool {
        self.is_closed.load(Ordering::SeqCst)
    }
}

impl<Codec, Header> RpcClient<Codec, Header>
where
    Codec: RpcCodec<Header>,
    Header: MessageHeaderTrait + Clone + Send + Sync + 'static,
{
    fn configure_tcp_socket(socket: &Socket) -> Result<(), io::Error> {
        socket.set_recv_buffer_size(16 * 1024 * 1024)?;
        socket.set_send_buffer_size(16 * 1024 * 1024)?;

        let keepalive = TcpKeepalive::new()
            .with_time(Duration::from_secs(5))
            .with_interval(Duration::from_secs(2))
            .with_retries(2);
        socket.set_tcp_keepalive(&keepalive)?;
        socket.set_nodelay(true)?;
        socket.set_nonblocking(true)?;

        Ok(())
    }

    pub async fn establish_connection(addr: String) -> Result<Self, RpcError>
    where
        Header: Default,
    {
        const MAX_CONNECTION_RETRIES: usize = 100 * 3600 * 24;
        let start = std::time::Instant::now();
        let retry_strategy = FixedInterval::from_millis(10)
            .map(jitter)
            .take(MAX_CONNECTION_RETRIES);

        debug!(rpc_type=%Codec::RPC_TYPE, %addr, "Trying to connect to rpc server");

        let client = Retry::spawn(retry_strategy, || async {
            let socket_addr = Self::resolve_address(&addr).await?;
            let stream = tokio::net::TcpStream::connect(socket_addr).await?;

            let std_stream = stream.into_std().map_err(RpcError::IoError)?;
            let socket = Socket::from(std_stream);
            Self::configure_tcp_socket(&socket).map_err(RpcError::IoError)?;
            let std_stream: std::net::TcpStream = socket.into();
            let configured_stream =
                tokio::net::TcpStream::from_std(std_stream).map_err(RpcError::IoError)?;

            Self::new_internal_tokio(configured_stream).await
        })
        .await
        .map_err(|e| {
            warn!(rpc_type = %Codec::RPC_TYPE, addr = %addr, error = %e, "failed to connect RPC server");
            RpcError::IoError(io::Error::other(e.to_string()))
        })?;

        let duration = start.elapsed();
        if duration > Duration::from_secs(1) {
            warn!(
                rpc_type = %Codec::RPC_TYPE,
                addr = %addr,
                duration_ms = %duration.as_millis(),
                "Slow connection establishment to RPC server"
            );
        } else if duration > Duration::from_millis(100) {
            debug!(
                rpc_type = %Codec::RPC_TYPE,
                addr = %addr,
                duration_ms = %duration.as_millis(),
                "Connection established to RPC server"
            );
        }

        Ok(client)
    }
}
